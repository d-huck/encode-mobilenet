{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encodec import EncodecModel\n",
    "from encodec.utils import convert_audio\n",
    "from mobilenetv3.mobilenetv3 import hswish, hsigmoid, SeModule, Block\n",
    "\n",
    "import torchaudio\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import IPython\n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Data\n",
    "\n",
    "GTZAN is a good classification dataset for development. It consists of audio/text pairs of music/genre and is a fairly easy task to hit mid-high 90s on given MFCCs or waveforms. If you have already run the following blocks, you can collapse and start at the next header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhuck/.pyenv/versions/3.8.11/envs/thesis/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "gtzan = load_dataset(\"marsyas/gtzan\")\n",
    "encoder = EncodecModel.encodec_model_24khz()\n",
    "\n",
    "def pre_process_gtzan(gtzan: DatasetDict, target_sr, target_channels) -> (list, list):\n",
    "    \"\"\"\n",
    "    Pre-load the data and process it to the correct sample rate and mono/stereo.\n",
    "    Returns the pre processed data and a list of the targets.\n",
    "    \"\"\"\n",
    "    data, targets = [], []\n",
    "    for x in tqdm(gtzan['train']):\n",
    "        audio, sr = torchaudio.load(x['file'])\n",
    "        audio = convert_audio(audio, sr, target_sr, target_channels)\n",
    "        audio = audio.narrow(-1, 0, 718368)\n",
    "        data.append(audio.unsqueeze(0))\n",
    "        targets.append(x['genre'])\n",
    "        \n",
    "    return data, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/999 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 999/999 [00:17<00:00, 58.45it/s]\n"
     ]
    }
   ],
   "source": [
    "data, targets = pre_process_gtzan(gtzan, encode.sample_rate, encode.channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhuck/.pyenv/versions/3.8.11/envs/thesis/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-encoding training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 27/125 [02:40<09:34,  5.86s/it]"
     ]
    }
   ],
   "source": [
    "class GTZANDataset(Dataset):\n",
    "    def __init__(self, data, labels, encoder, device=None):\n",
    "        super().__init__()\n",
    "        data = [torch.tensor(x).to(torch.int) for x in data]\n",
    "        \n",
    "        self.labels = [torch.tensor(x) for x in labels]\n",
    "        \n",
    "        if device is None:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.encodings)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "            encoding = self.encodings[index].to(self.device)\n",
    "            target = self.labels[index].to(self.device)\n",
    "            \n",
    "            return encoding, target\n",
    "\n",
    "def encode_data(data, encoder, batch_size=8, device=None):\n",
    "    print(\"Pre-encoding training data\")\n",
    "    \n",
    "    encodings = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(data), batch_size)):\n",
    "            batch = torch.cat(data[i:i+batch_size], dim=0).to(device)\n",
    "            encoded_frames = encoder.encode(batch)\n",
    "            \n",
    "            codes = torch.cat([e[0] for e in encoded_frames], dim=-1)\n",
    "            encodings.append(codes)\n",
    "            \n",
    "    return encodings\n",
    "\n",
    "# This takes about 15 minutes to run on a M1 Macbook Pro, a couple of minutes for a GPU\n",
    "encoder = EncodecModel.encodec_model_24khz()\n",
    "encoder.set_target_bandwidth(1.5)\n",
    "encodings = encode_data(data, encoder, batch_size=8, device=device)\n",
    "torch.save(encodings, \"gtzan_encodings.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, batch_size=32, random_seed=42, device=None, valid_size=0.1, test_size=0.05, shuffle=True):\n",
    "            \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=random_seed)\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=valid_size, random_state=random_seed)\n",
    "\n",
    "    print(\"Creating trainng set...\")\n",
    "    train = GTZANDataset(x_train, y_train, device=device)\n",
    "    print(\"Creating validation set...\")\n",
    "    valid = GTZANDataset(x_valid, y_valid, device=device)\n",
    "    print(\"Creating testing set...\")\n",
    "    test = GTZANDataset(x_test, y_test, device=device)\n",
    "    \n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid, batch_size=batch_size, shuffle=True)\n",
    "    test_loader  = DataLoader(test,  batch_size=batch_size, shuffle=True)\n",
    "    return train_loader, valid_loader, test_loader\n",
    "\n",
    "data = torch.load(\"gtzan_encodings.pt\")\n",
    "train, valid, test = split_data(data, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
