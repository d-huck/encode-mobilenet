{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encodec import EncodecModel\n",
    "from encodec.utils import convert_audio\n",
    "from mobilenetv3.mobilenetv3 import hswish, hsigmoid, SeModule, Block\n",
    "\n",
    "import torchaudio\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import IPython\n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Data\n",
    "\n",
    "GTZAN is a good classification dataset for development. It consists of audio/text pairs of music/genre and is a fairly easy task to hit mid-high 90s on given MFCCs or waveforms. This section sets up the dataset. The only reason to run it is if you need to generate encodings at a higher bitrate for further development. The 1.5 bitrate target is already prepared in this repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtzan = load_dataset(\"marsyas/gtzan\")\n",
    "encoder = EncodecModel.encodec_model_24khz()\n",
    "\n",
    "def pre_process_gtzan(gtzan: DatasetDict, target_sr, target_channels) -> (list, list):\n",
    "    \"\"\"\n",
    "    Pre-load the data and process it to the correct sample rate and mono/stereo.\n",
    "    Returns the pre processed data and a list of the targets.\n",
    "    \"\"\"\n",
    "    data, targets = [], []\n",
    "    for x in tqdm(gtzan['train']):\n",
    "        audio, sr = torchaudio.load(x['file'])\n",
    "        audio = convert_audio(audio, sr, target_sr, target_channels)\n",
    "        audio = audio.narrow(-1, 0, 718368)\n",
    "        data.append(audio.unsqueeze(0))\n",
    "        targets.append(x['genre'])\n",
    "        \n",
    "    return data, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = pre_process_gtzan(gtzan, encode.sample_rate, encode.channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhuck/.pyenv/versions/3.8.11/envs/thesis/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-encoding training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/dhuck/cs.utexas.edu/homework/final/Training.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dhuck/cs.utexas.edu/homework/final/Training.ipynb#W5sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m encoder \u001b[39m=\u001b[39m EncodecModel\u001b[39m.\u001b[39mencodec_model_24khz()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dhuck/cs.utexas.edu/homework/final/Training.ipynb#W5sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m encoder\u001b[39m.\u001b[39mset_target_bandwidth(\u001b[39m1.5\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/dhuck/cs.utexas.edu/homework/final/Training.ipynb#W5sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m encodings \u001b[39m=\u001b[39m encode_data(data, encoder, batch_size\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m, device\u001b[39m=\u001b[39;49mdevice)\n",
      "\u001b[1;32m/Users/dhuck/cs.utexas.edu/homework/final/Training.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dhuck/cs.utexas.edu/homework/final/Training.ipynb#W5sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dhuck/cs.utexas.edu/homework/final/Training.ipynb#W5sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(data), batch_size)):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/dhuck/cs.utexas.edu/homework/final/Training.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m         batch \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(data[i:i\u001b[39m+\u001b[39;49mbatch_size], dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dhuck/cs.utexas.edu/homework/final/Training.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m         encoded_frames \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39mencode(batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dhuck/cs.utexas.edu/homework/final/Training.ipynb#W5sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m         codes \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([e[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m encoded_frames], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "def encode_data(data, encoder, batch_size=8, device=None):\n",
    "    print(\"Pre-encoding training data\")\n",
    "    \n",
    "    encodings = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(data), batch_size)):\n",
    "            batch = torch.cat(data[i:i+batch_size], dim=0).to(device)\n",
    "            encoded_frames = encoder.encode(batch)\n",
    "            \n",
    "            codes = torch.cat([e[0] for e in encoded_frames], dim=-1)\n",
    "            encodings.append(codes)\n",
    "    \n",
    "    encodings = torch.cat(encodings, dim=0)\n",
    "    return encodings\n",
    "\n",
    "# This takes about 15 minutes to run on a M1 Macbook Pro, a couple of minutes for a GPU\n",
    "encoder = EncodecModel.encodec_model_24khz()\n",
    "encoder.set_target_bandwidth(1.5)\n",
    "encodings = encode_data(data, encoder, batch_size=8, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 2, 2245])\n"
     ]
    }
   ],
   "source": [
    "print(encodings[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    'data': encodings,\n",
    "    'targets': targets\n",
    "}\n",
    "torch.save(dataset, \"gtzan_encodings.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTZANDataset(Dataset):\n",
    "    def __init__(self, data, labels, device=None):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        \n",
    "        self.labels = [torch.tensor(x) for x in labels]\n",
    "        \n",
    "        if device is None:\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "            data = self.data[index].to(self.device)\n",
    "            target = self.labels[index].to(self.device)\n",
    "            \n",
    "            return data, target\n",
    "\n",
    "def split_data(data, batch_size=32, random_seed=42, device=None, valid_size=0.1, test_size=0.05, shuffle=True):\n",
    "    x = data['data']\n",
    "    y = data['targets']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=random_seed)\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=valid_size, random_state=random_seed)\n",
    "\n",
    "    train = GTZANDataset(x_train, y_train, device=device)\n",
    "    valid = GTZANDataset(x_valid, y_valid, device=device)\n",
    "    test = GTZANDataset(x_test, y_test, device=device)\n",
    "    \n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid, batch_size=batch_size, shuffle=True)\n",
    "    test_loader  = DataLoader(test,  batch_size=batch_size, shuffle=True)\n",
    "    return train_loader, valid_loader, test_loader\n",
    "\n",
    "data = torch.load(\"./gtzan_encodings-1.5.data\")\n",
    "train, valid, test = split_data(data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
